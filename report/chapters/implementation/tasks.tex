\subsection{Task-based Scheduler}\label{sec:impl:tasks}
	As each \emph{compute} node has multiple cores, the workload can be distributed across them. These so-called worker threads work on the following tasks until there are no more tasks available.
	\begin{enumerate}
		\item In the \emph{simulation} task, the worker thread simulates a configuration, thermalizes and blocks the results, and writes back the iid samples of $E$, $E^2$, $M$, $M^2$, and $\Upsilon$ to the database. Additionally the final spin arrays are also written to the database, which fixes shortcomings~\cref{shortcomings:bootstrap,shortcomings:sweeps}.
		\item In the \emph{bootstrap} task, the worker threads retrieve the iid samples for each configuration that was simulated beforehand. The samples are bootstrapped, and the final results are written to the database.
		\item In the \emph{derivative} task, the workers calculate the observables ($C_V$, $\chi$) derived from the bootstrapped results.
	\end{enumerate}
	These steps are executed in stages, so initially, all worker threads focus on \emph{simulation} tasks until none remain. As soon as all the compute nodes' worker threads have finished with one type of task, they can proceed to the following kind of task. Note that the worker threads may work on configurations belonging to different lattice sizes, which fixes shortcoming~\cref{shortcomings:cores}.
	
	As the pipeline finishes, the \emph{compute} nodes wait for each other in a synchronization step. From here, they go back to~\cref{scanning:iter} of the temperature scanning procedure. If the exit condition $I_C \ge I_\text{max}$ is fulfilled, the \emph{compute} nodes exit.

	\subsubsection{Chunking}\label{sec:impl:tasks:chunks}
		The \emph{simulation} task uses chunking to alleviate~\cref{shortcomings:crashed} discussed earlier in the chapter. The total number of sweeps is defined here as the product of the number of sweeps per chunk and the number of chunks $N_\text{Chunks}$, which can be set in the config file. The worker threads work on a given configuration, one chunk at a time, and write back the intermediate results and the current spins to the database. This way, another worker can continue working on a configuration when the original worker crashes. Splitting the workload into chunks ensures that if a node should fail, only a subset of iid samples is lost.

	\subsubsection{Scheduling}
		A task scheduler was implemented, which delegates the workload to the worker threads. The number of worker threads equals the number of CPU cores available to the program. A dedicated scheduling thread is started, which connects to the database. The task distribution works as follows:
		\begin{enumerate}
			\item The worker threads register themselves as available.
			\item \label{scheduler_loop} The scheduling thread searches for any available worker threads.
				\begin{enumerate}
					\item If a worker is available, the next task is fetched and delegated to the available worker.
					\item If no worker is available, the scheduling thread sleeps for one second.
				\end{enumerate}
			\item The scheduling tasks check if the worker threads have published any results and write them to the database.
			\item Go to~\cref{scheduler_loop} unless all workers are waiting and no new tasks are available.
		\end{enumerate}